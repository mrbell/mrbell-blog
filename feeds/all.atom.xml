<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Michael Bell</title><link href="http://michaelryanbell.com/" rel="alternate"></link><link href="http://michaelryanbell.com/feeds/all.atom.xml" rel="self"></link><id>http://michaelryanbell.com/</id><updated>2017-06-25T00:00:00-04:00</updated><entry><title>I'm afraid to write on the internet</title><link href="http://michaelryanbell.com/fear-of-blogging.html" rel="alternate"></link><published>2017-06-25T00:00:00-04:00</published><updated>2017-06-25T00:00:00-04:00</updated><author><name>Michael Bell</name></author><id>tag:michaelryanbell.com,2017-06-25:/fear-of-blogging.html</id><summary type="html">

&lt;p&gt;I don't post on this site much and that bothers me. I want to write more, often have ideas for things to write about, and may even jot down some notes and thoughts, but rarely get around to posting things. Why? To be honest, I don't post here mostly because I'm kind of afraid to.&lt;/p&gt;
</summary><content type="html">

&lt;p&gt;I don't post on this site much and that bothers me. I want to write more, often have ideas for things to write about, and may even jot down some notes and thoughts, but rarely get around to posting things. Why? To be honest, I don't post here mostly because I'm kind of afraid to.&lt;/p&gt;


&lt;p&gt;I worry I don't have anything interesting or unique to say. That's probably true, but as I think about it, who cares? I don't write professionally, to gain a following, entertain, or impress people. I write because it helps me think. I don't have to blog to write of course, but publishing my writing forces me to spend a little more time thinking things through to the end and organizing my thoughts. As a side benefit, if people find something I write interesting or helpful, that's awesome. But if not, that shouldn't stop me. The exercise is useful in and of itself.&lt;/p&gt;
&lt;p&gt;I also worry that I might say something that's wrong or offend someone. This concern actually governs all of my online activities, or lack thereof. I can be pretty insecure about being wrong, or exposing myself to criticism in general. I worry that if I make a mistake or admit I don't know something then people will think less of me. The fact is that I will be wrong on occasion, and because this is the internet, someone will probably think I'm an idiot because of it. But I know better than to be concerned about that. Everyone makes mistakes, and reasonable people understand that. No one knows everything, and I think reasonable people understand that, too. After all, people that know me seem to think I'm reasonably competent despite the fact that I screw up or say dumb things pretty regularly. Why do I care what unreasonable people think? I should get over it.&lt;/p&gt;
&lt;p&gt;Another concern (that is probably an excuse to avoid confronting the fears discussed above) is that I need to pick a topic and stick with it. My "audience" will be confused or turned off if I'm posting about stats one day and video games the next. I don't have an audience though, and again that's not why I want to do this in the first place. I think about and am interested in a lot of different things. If I restrict myself to writing about one thing, I'm never going to do it. Which brings us to where we are today.&lt;/p&gt;
&lt;p&gt;These are a few of the fears and excuses that keep me from blogging, and engaging online in general. I'm going to work on getting over them. I'm not going to commit to writing with any frequency or anything, but I'll stop worrying so much about the topic, making mistakes, being ultra thorough, etc. If I'm open to just writing about what's on my mind without worrying so much, I'm sure I'll find many more opportunities to post than I do now. Let's see.&lt;/p&gt;</content><category term="writing"></category><category term="thoughts"></category></entry><entry><title>Bayesian A/B testing with confidence</title><link href="http://michaelryanbell.com/bayesian_ab_testing.html" rel="alternate"></link><published>2015-12-27T00:00:00-05:00</published><updated>2015-12-30T00:00:00-05:00</updated><author><name>Michael Bell</name></author><id>tag:michaelryanbell.com,2015-12-27:/bayesian_ab_testing.html</id><summary type="html">

&lt;p&gt;I have been developing the A/B testing procedure that I want to use in
an upcoming experiment at work. Generally speaking I'm on team Bayes when it comes
to statistical matters, and that's the approach that I will take in this case as well. In
this (long) post I'll outline a method for Bayesian A/B testing that is largely built on some
excellent blog posts by &lt;a href="http://www.evanmiller.org/bayesian-ab-testing.html"&gt;Evan Miller&lt;/a&gt;,
&lt;a href="https://www.chrisstucchio.com/blog/2014/bayesian_ab_decision_rule.html"&gt;Chris Stuccio&lt;/a&gt;,
and &lt;a href="http://varianceexplained.org/r/bayesian-ab-testing/"&gt;David Robinson&lt;/a&gt;.
In this post I'll summarize the results of Miller and Stuccio, ending up with a
decision function for A/B testing based on the gain expected from making the
change that is under consideration. I go a bit further than the referenced posts
by deriving a measure of uncertainty in the expected gain that can be used to
determine when a result is significant and overcome the "peeking" problem discussed
in Robinson's post. Lastly I calculate the expected difference between the two
procedures under test (as opposed to the gain which is the difference but
only when the new procedure is better).
Throughout I present some simulated examples to give a sense of the impact of the
different parameters in the model and to illustrate some aspects of the model
that one should be aware of.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;&lt;strong&gt;UPDATE (12/30/2015)&lt;/strong&gt;: In response to a comment by Niels Oppermann, I have added
derivations of the expected difference &lt;span class="math"&gt;\(p_B-p_A\)&lt;/span&gt; in addition to the
expected gain &lt;span class="math"&gt;\(\mathrm{max}\left(p_B-p_A, 0\right)\)&lt;/span&gt; (i.e. the difference when
&lt;span class="math"&gt;\(p_B&amp;gt;p_A\)&lt;/span&gt;).&lt;/p&gt;


&lt;p&gt;I have been developing the A/B testing procedure that I want to use in
an upcoming experiment at work. Generally speaking I'm on team Bayes when it comes
to statistical matters, and that's the approach that I will take in this case as well. In
this (long) post I'll outline a method for Bayesian A/B testing that is largely built on some
excellent blog posts by &lt;a href="http://www.evanmiller.org/bayesian-ab-testing.html"&gt;Evan Miller&lt;/a&gt;,
&lt;a href="https://www.chrisstucchio.com/blog/2014/bayesian_ab_decision_rule.html"&gt;Chris Stuccio&lt;/a&gt;,
and &lt;a href="http://varianceexplained.org/r/bayesian-ab-testing/"&gt;David Robinson&lt;/a&gt;.
In this post I'll summarize the results of Miller and Stuccio, ending up with a
decision function for A/B testing based on the gain expected from making the
change that is under consideration. I go a bit further than the referenced posts
by deriving a measure of uncertainty in the expected gain that can be used to
determine when a result is significant and overcome the "peeking" problem discussed
in Robinson's post. Lastly I calculate the expected difference between the two
procedures under test (as opposed to the gain which is the difference but
only when the new procedure is better).
Throughout I present some simulated examples to give a sense of the impact of the
different parameters in the model and to illustrate some aspects of the model
that one should be aware of.&lt;/p&gt;


&lt;h2&gt;The basic model&lt;/h2&gt;
&lt;p&gt;In an A/B test, one has two different procedures (i.e. treatments) under consideration
and would like to know which one produces the best results. For example, an e-commerce
company might have a couple of different web site layouts that they are considering
and would like to know which one has the best click through rate to a product page.
An experiment is run where two groups are selected at random from the overall
population. The control group A uses the standard procedure and the test group B
uses the new procedure. At the end of the experiment the data is analyzed to
decide whether the outcome for group B was better (or worse, or the same)
than the outcome for group A.&lt;/p&gt;
&lt;p&gt;In the simplest case, which I consider here, the outcome is binary,
e.g. either a customer clicked through to a product page or they didn't.
In this case, the most natural choice for the &lt;em&gt;likelihood&lt;/em&gt;, i.e. the
probability that a number of positive outcomes &lt;em&gt;k&lt;/em&gt; is observed from a total
of &lt;em&gt;n&lt;/em&gt; trials with probability of success &lt;em&gt;p&lt;/em&gt; per trial, is the Binomial distribution&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}P(k|n,p)=\mathrm{Binomial}(k;n,p)=\left(\begin{array}{c}n\\k\end{array}\right)p^{k}\left(1-p\right)^{n-k}.\end{equation}&lt;/div&gt;
&lt;p&gt;Of course &lt;em&gt;n&lt;/em&gt; and &lt;em&gt;k&lt;/em&gt; can be measured experimentally, but &lt;em&gt;p&lt;/em&gt; must be inferred.
It's time for Bayes' theorem (the important bit of it anyway)&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}P\left(p|k,n\right)\propto P(k|n,p)P(p)\end{equation}&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(P(p)\)&lt;/span&gt; describes any prior knowledge about &lt;em&gt;p&lt;/em&gt;. A convenient choice of
prior distribution is the Beta distribution which is conjugate to the Binomial
distribution&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}P(p)=\mathrm{Beta}(p;\alpha,\beta)=\frac{p^{\alpha-1}(1-p)^{\beta-1}}{\mathrm{B}(\alpha,\beta)}\end{equation}&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; are parameters of the Beta distribution and
&lt;span class="math"&gt;\(\mathrm{B}(\alpha,\beta)\)&lt;/span&gt; is the &lt;a href="https://en.wikipedia.org/wiki/Beta_function"&gt;Beta function&lt;/a&gt;.
The parameters &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; can be set empirically from historical data,
using hierarchical modeling, or chosen manually. For instance, a uniform prior
on the interval [0,1] can be chosen by setting &lt;span class="math"&gt;\(\alpha=1\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta=1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A Binomial likelihood and Beta prior leads to a posterior distribution that is also Beta
distributed&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}P\left(p|k,n\right)=p^{k+\alpha-1}\left(1-p\right)^{n-k+\beta-1}=\mathrm{Beta}(p;\alpha+k,n-k+\beta)=\mathrm{Beta}(p;\alpha',\beta')\end{equation}&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\alpha'=\alpha+k\)&lt;/span&gt; is the prior parameter &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; plus the number of
successful trials and &lt;span class="math"&gt;\(\beta'=n-k+\beta\)&lt;/span&gt; is the prior parameter
&lt;span class="math"&gt;\(\beta\)&lt;/span&gt; plus the number of failed trials.&lt;/p&gt;
&lt;p&gt;The figure below shows the posterior distributions for &lt;span class="math"&gt;\(p_{A}\)&lt;/span&gt; and &lt;span class="math"&gt;\(p_{B}\)&lt;/span&gt;
for a simulated data set with &lt;span class="math"&gt;\(n=500\)&lt;/span&gt; observations. I have chosen a true &lt;span class="math"&gt;\(p_{A}\)&lt;/span&gt; of 0.5, a true &lt;span class="math"&gt;\(p_{B}\)&lt;/span&gt;
of 0.55, and a prior distribution such that p is expected to most likely fall
between 0.4 and 0.6 with a mean of 0.5. The posterior mean approaches
the ratio &lt;span class="math"&gt;\(k/n\)&lt;/span&gt; in each case, but there is still some influence of the prior
given the limited amount of data. With more and more data, the posterior
distribution will become centered on the ratio &lt;span class="math"&gt;\(k/n\)&lt;/span&gt; and increasingly more narrow.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Example Posterior Inference" src="http://michaelryanbell.com/images/example_posterior_inference.png"&gt;&lt;/p&gt;
&lt;h2&gt;The probability that the new procedure is better&lt;/h2&gt;
&lt;p&gt;Given the experimental data and the posterior distributions for p, how does one know
that the new procedure is better than the old one i.e. that &lt;span class="math"&gt;\(p_{B}&amp;gt;p_{A}\)&lt;/span&gt;? If you
were looking at a plot like the one above after an experiment, with the max of &lt;span class="math"&gt;\(P(p_B | n_B, k_B)\)&lt;/span&gt;
clearly higher than that of &lt;span class="math"&gt;\(P(p_A | n_A, k_A)\)&lt;/span&gt; but some overlap in the distributions, what
would you do? How confident are you that the new treatment is better than the
baseline? How much better is it?&lt;/p&gt;
&lt;p&gt;To answer these questions I follow the approach outlined in
&lt;a href="http://www.evanmiller.org/bayesian-ab-testing.html"&gt;a blog post by Evan Miller&lt;/a&gt;,
namely to calculate the probability &lt;span class="math"&gt;\(P\left(p_{B}&amp;gt;p_{A}\right)\)&lt;/span&gt;, which is&lt;/p&gt;
&lt;div class="math"&gt;\begin{align}P\left(p_{B}&amp;gt;p_{A}\right)&amp;amp;=\int_{0}^{1}\int_{p_{A}}^{1}dp_{A}dp_{B}\frac{p_{A}^{\alpha'_{A}-1}(1-p_{A})^{\beta'_{A}-1}}{\mathrm{B}(\alpha'_{A},\beta'_{A})}\frac{p_{B}^{\alpha'_{B}-1}(1-p_{B})^{\beta'_{B}-1}}{\mathrm{B}(\alpha'_{B},\beta'_{B})}\\
&amp;amp;=\sum_{i=0}^{\alpha'_{B}-1}\frac{\mathrm{B}\left(\alpha'_{A}+i,\beta'_{A}+\beta'_{B}\right)}{\left(\beta'_{B}+i\right)\mathrm{B}\left(1+i,\beta'_{B}\right)\mathrm{B}\left(\alpha_{A},\beta_{A}\right)}\\
&amp;amp;=h(\alpha'_{A},\beta'_{A},\alpha'_{B},\beta'_{B}).\end{align}&lt;/div&gt;
&lt;p&gt;See the original post for a detailed derivation. I'll call this quantity the
&lt;em&gt;probability of improvement (POI)&lt;/em&gt;. Note that I'm generally interested
in the probability that the new procedure, applied to group B, is &lt;em&gt;better&lt;/em&gt; than the
standard procedure applied to group A. I could alternatively consider how likely
it is that it's worse and I'm making a mistake by adopting the new procedure.
In this case I simply swap the A and B labels above.&lt;/p&gt;
&lt;p&gt;The POI is an interesting metric, but it's not ideally suited for making decisions.
It indicates only that one procedure is better than another, but not by how much.
A marginal improvement may not justify a change
to the current procedure, so if B is only slightly better than A, I would like to know.
Actually, in case the two procedures are indeed the same then the POI turns out to be a very unreliable metric.&lt;/p&gt;
&lt;p&gt;The figure below shows the range of POIs from 100 simulated experiments as calculated every 1000 trials
(e.g. page views for the e-commerce example) up to 80,000 trials.
In this case the true values of &lt;span class="math"&gt;\(p_A\)&lt;/span&gt; and &lt;span class="math"&gt;\(p_B\)&lt;/span&gt; are both 0.5.
I show the average value from all 100 simulations at each value of &lt;span class="math"&gt;\(n\)&lt;/span&gt; together with the
intervals covering 65% and 95% of all observed values.&lt;/p&gt;
&lt;p&gt;&lt;img alt="POI with equal probabilities for each group" src="http://michaelryanbell.com/images/poi_equal_probabilities.png"&gt;&lt;/p&gt;
&lt;p&gt;The simulations show that nearly any POI can be observed
when the two procedures truly have the same effect. Judging solely on POI,
there is a decent chance that one could observe &lt;span class="math"&gt;\(p_B\)&lt;/span&gt; to be greater than &lt;span class="math"&gt;\(p_A\)&lt;/span&gt;
when in fact it is not. What is surprising to me is that the spread of results
never narrows. Running a longer test wont reduce the chance that a high POI
will be reported.&lt;/p&gt;
&lt;h2&gt;How much better is the new procedure?&lt;/h2&gt;
&lt;p&gt;So POI isn't a great metric to base decisions on. Instead, I will
use the &lt;em&gt;expected gain&lt;/em&gt; to evaluate our results as described &lt;a href="https://www.chrisstucchio.com/blog/2014/bayesian_ab_decision_rule.html"&gt;in a blog post by Chris Stuccio&lt;/a&gt;.
Note that the referenced article actually considers the expected loss. Again I am interested
in calculating how much better the new procedure is from the baseline, not whether
it is worse, so I'll work with the expected gain. Again, the difference is in
the order of the B and A labels in the expressions below.&lt;/p&gt;
&lt;p&gt;The expected gain extends the concept of POI to not only include the probability
that one outcome is better than the other,
but also how much better the outcome will be. The metric is defined as
&lt;span class="math"&gt;\(P\left(\mathrm{max}\left[p_B - p_A, 0\right]\right)\)&lt;/span&gt;&lt;/p&gt;
&lt;div class="math"&gt;\begin{align}P\left(\mathrm{max}\left[p_B-p_A,0\right]\right)&amp;amp;=\int_{0}^{1}\int_{0}^{1}dp_{A}dp_{B}\mathrm{max}\left[\left(p_{B}-p_{A}\right),\,0\right]\frac{p_{A}^{\alpha'_{A}-1}(1-p_{A})^{\beta'_{A}-1}}{\mathrm{B}(\alpha'_{A},\beta'_{A})}\frac{p_{B}^{\alpha'_{B}-1}(1-p_{B})^{\beta'_{B}-1}}{\mathrm{B}(\alpha'_{B},\beta'_{B})}\\
&amp;amp;=\int_{0}^{1}\int_{p_{A}}^{1}dp_{A}dp_{B}\left(p_{B}-p_{A}\right)\frac{p_{A}^{\alpha'_{A}-1}(1-p_{A})^{\beta'_{A}-1}}{\mathrm{B}(\alpha'_{A},\beta'_{A})}\frac{p_{B}^{\alpha'_{B}-1}(1-p_{B})^{\beta'_{B}-1}}{\mathrm{B}(\alpha'_{B},\beta'_{B})}\\
&amp;amp;=\frac{\mathrm{B}(\alpha'_{B}+1,\beta'_{B})}{\mathrm{B}(\alpha'_{B},\beta'_{B})}h(\alpha'_{A},\beta'_{A},\alpha'_{B}+1,\beta'_{B})-\frac{\mathrm{B}(\alpha'_{A}+1,\beta'_{A})}{\mathrm{B}(\alpha'_{A},\beta'_{A})}h(\alpha'_{A}+1,\beta'_{A},\alpha'_{B},\beta'_{B})\\
&amp;amp;=\frac{\alpha'_{B}}{\alpha'_{B}+\beta'_{B}}h(\alpha'_{A},\beta'_{A},\alpha'_{B}+1,\beta'_{B})-\frac{\alpha'_{A}}{\alpha'_{A}+\beta'_{A}}h(\alpha'_{A}+1,\beta'_{A},\alpha'_{B},\beta'_{B})\end{align}&lt;/div&gt;
&lt;p&gt;where I have used the property of the Beta function&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}\mathrm{B}\left(\alpha+1,\beta\right)=\mathrm{B}\left(\alpha,\beta\right)\frac{\alpha}{\alpha+\beta}.\end{equation}&lt;/div&gt;
&lt;p&gt;The expected gain can be used to evaluate the outcome of an experiment. When reporting
to decision makers, this outcome not only says that B turned out better than A, but
it also provides an estimate of how much better it is.&lt;/p&gt;
&lt;p&gt;What happens to the expected gain when the true values of &lt;span class="math"&gt;\(p_B\)&lt;/span&gt; and &lt;span class="math"&gt;\(p_A\)&lt;/span&gt; are equal?
The POI wasn't always reliable in this situation. Is the gain a better metric?
I'll turn again to simulated experimental results to find out.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Expected gain with equal probabilities for each group" src="http://michaelryanbell.com/images/gain_equal_probabilities.png"&gt;&lt;/p&gt;
&lt;p&gt;It's clear that the gain behaves much better than the POI did above. The gain
quickly falls to a small value relatively quickly, and drops closer to the
true value of 0 as the experiment continues. When looking for, say, a
1% gain from a new procedure, this metric would rightly indicate that such a
gain was not likely.&lt;/p&gt;
&lt;h2&gt;On "peeking" and uncertainty in the gain&lt;/h2&gt;
&lt;p&gt;It has been suggested that one can "peek" at the gain throughout the experiment
to watch for it to go above some threshold value, but
&lt;a href="http://varianceexplained.org/r/bayesian-ab-testing/"&gt;this post by David Robinson&lt;/a&gt;
shows through a series of simulations that this practice leads to an excessive rate of false positives
(although the excessive false positive rate is not as extreme as if one were
peeking at a &lt;em&gt;p&lt;/em&gt;-value).&lt;/p&gt;
&lt;p&gt;I'll give an example. Say we are running an experiment
and are interested in implementing a new procedure (applied to group B) if we find a 1% gain
in &lt;span class="math"&gt;\(p_B\)&lt;/span&gt; over &lt;span class="math"&gt;\(p_A\)&lt;/span&gt;. But let's imagine that &lt;span class="math"&gt;\(p_B\)&lt;/span&gt; is actually 1% &lt;em&gt;lower&lt;/em&gt; than
&lt;span class="math"&gt;\(p_A\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Gain as a function of experiment length when B is worse than A." src="http://michaelryanbell.com/images/gain_B_is_worse.png"&gt;&lt;/p&gt;
&lt;p&gt;The figure above shows the expected gain from 100 simulated experiments where again
I "peek" at the gain every 1000 trials. Until about 5000 trials
there is a good chance that a 1% gain in B over A can be observed, and if I saw that
and decided to stop the experiment early declaring success I would be making a mistake. The
longer the experiment, the less likely it is that such a mistake would be made.
But if I were watching the data to see a 1% gain and stopped the experiment as
soon as I did, I would end up making a lot of bad decisions.&lt;/p&gt;
&lt;p&gt;In the simulated examples above it is clear that with limited data, the variance
in the observed expected gain in repeated experiments is too large
and as a result reasonable decisions can't be made. How does one know when the result is "significant"?
If the variance was known to be large and therefore the estimate of expected gain was inaccurate, then it would
be obvious that more data was needed. Simulations can provide estimates of the
variance, as above, but the variance in &lt;span class="math"&gt;\(\mathrm{max}\left[p_B - p_A, 0\right]=\delta_{BA}\)&lt;/span&gt; can also be
calculated directly&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}P\left[\left(\delta_{BA}-\bar{\delta}_{BA}\right)^{2}\right]=\int_{0}^{1}\int_{p_{A}}^{1}dp_{A}dp_{B}\left(p_{B}-p_{A}-\bar{\delta}_{BA}\right)^{2}\frac{p_{A}^{\alpha'_{A}-1}(1-p_{A})^{\beta'_{A}-1}}{\mathrm{B}(\alpha'_{A},\beta'_{A})}\frac{p_{B}^{\alpha'_{B}-1}(1-p_{B})^{\beta'_{B}-1}}{\mathrm{B}(\alpha'_{B},\beta'_{B})}\end{equation}&lt;/div&gt;
&lt;p&gt;The derivation proceeds very similarly to that of the expected gain&lt;/p&gt;
&lt;div class="math"&gt;\begin{align}P\left[\left(\delta_{BA}-\bar{\delta}_{BA}\right)^{2}\right]=&amp;amp;\frac{\alpha'_{B}\left(\alpha'_{B}+1\right)}{\left(\alpha'_{B}+\beta'_{B}\right)\left(\alpha'_{B}+\beta'_{B}+1\right)}h(\alpha'_{A},\beta'_{A},\alpha'_{B}+2,\beta'_{B})\ldots\notag\\
&amp;amp;+\frac{\alpha'_{A}\left(\alpha'_{A}+1\right)}{\left(\alpha'_{A}+\beta'_{A}\right)\left(\alpha'_{A}+\beta'_{A}+1\right)}h(\alpha'_{A}+2,\beta'_{A},\alpha'_{B},\beta'_{B})\ldots\notag\\
&amp;amp;+\bar{\delta}_{BA}^{2}h(\alpha'_{A},\beta'_{A},\alpha'_{B},\beta'_{B})-2\frac{\alpha'_{A}}{\alpha'_{A}+\beta'_{A}}\frac{\alpha'_{B}}{\alpha'_{B}+\beta'_{B}}h(\alpha'_{A}+1,\beta'_{A},\alpha'_{B}+1,\beta'_{B})\ldots\notag\\
&amp;amp;+2\bar{\delta}_{BA}\frac{\alpha'_{A}}{\alpha'_{A}+\beta'_{A}}h(\alpha'_{A}+1,\beta'_{A},\alpha'_{B},\beta'_{B})-2\bar{\delta}_{BA}\frac{\alpha'_{B}}{\alpha'_{B}+\beta'_{B}}h(\alpha'_{A},\beta'_{A},\alpha'_{B}+1,\beta'_{B}).\end{align}&lt;/div&gt;
&lt;p&gt;The expected gain, together with it's variance given here, are well suited to
evaluating the experimental outcome. As an experiment is run
the expected gain and it's variance can be calculated. If the gain is found to be significant
&lt;em&gt;relative to&lt;/em&gt; the square root of the variance, then the experiment can safely be stopped.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Average gain together with uncertainty compared to variance observed in experiments with 5% gain." src="http://michaelryanbell.com/images/gain_w_uncert.png"&gt;&lt;/p&gt;
&lt;p&gt;In the figure above, I show the results of another set of 100 simulations. In this
case the true value of &lt;span class="math"&gt;\(p_B\)&lt;/span&gt; is 5% higher than &lt;span class="math"&gt;\(p_A\)&lt;/span&gt;. The average
of all observed gains converges on the correct difference pretty quickly. I also
show the observed spread in gains over the 100 simulations as the interval
covering 68% of the observed values and
the 1-&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; uncertainty as estimated by the square root of the variance calculated
using the equation above. The closed form "1-&lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;" uncertainty
calculation matches the spread of simulated results very closely. The figure
below is similar, but for a true &lt;span class="math"&gt;\(p_B\)&lt;/span&gt; that is only 1% higher than &lt;span class="math"&gt;\(p_A\)&lt;/span&gt; for
comparison.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Average gain together with uncertainty compared to variance observed in experiments with 1% gain." src="http://michaelryanbell.com/images/gain_w_uncert_1percent.png"&gt;&lt;/p&gt;
&lt;h2&gt;What's the difference?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Thanks to Niels Oppermann for motivating this section.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The expected gain and its variance have both been calculated under the condition that
&lt;span class="math"&gt;\(p_B&amp;gt;p_A\)&lt;/span&gt;. Instead, one could simply calculate the &lt;em&gt;expected difference&lt;/em&gt;
&lt;span class="math"&gt;\(p_B-p_A=\delta'_{BA}\)&lt;/span&gt; without specifying that the new procedure outperforms the standard procedure&lt;/p&gt;
&lt;div class="math"&gt;\begin{align}P\left(p_B-p_A\right)&amp;amp;=\int_{0}^{1}\int_{0}^{1}dp_{A}dp_{B}\left(p_{B}-p_{A}\right)\frac{p_{A}^{\alpha'_{A}-1}(1-p_{A})^{\beta'_{A}-1}}{\mathrm{B}(\alpha'_{A},\beta'_{A})}\frac{p_{B}^{\alpha'_{B}-1}(1-p_{B})^{\beta'_{B}-1}}{\mathrm{B}(\alpha'_{B},\beta'_{B})}\notag\\
&amp;amp;=\frac{\mathrm{B}(\alpha'_{B}+1,\beta'_{B})}{\mathrm{B}(\alpha'_{B},\beta'_{B})}-\frac{\mathrm{B}(\alpha'_{A}+1,\beta'_{A})}{\mathrm{B}(\alpha'_{A},\beta'_{A})}\notag\\
&amp;amp;=\frac{\alpha'_{B}}{\alpha'_{B}+\beta'_{B}}-\frac{\alpha'_{A}}{\alpha'_{A}+\beta'_{A}}\label{eq:exp_diff}\\
&amp;amp;=\bar{\delta}'_{BA}\label{eq:exp_diff2}\end{align}&lt;/div&gt;
&lt;p&gt;This is just the difference between the posterior means for &lt;span class="math"&gt;\(p_B\)&lt;/span&gt; and &lt;span class="math"&gt;\(p_A\)&lt;/span&gt; as
one might intuitively expect. What about the variance? The derivation is similar
to the variance in the gain and the result is similar except a bit cleaner without the
&lt;span class="math"&gt;\(h(\alpha_A, \beta_A, \alpha_B, \beta_B)\)&lt;/span&gt; terms.&lt;/p&gt;
&lt;div class="math"&gt;\begin{align}P\left[\left(\delta'_{BA}-\bar{\delta}'_{BA}\right)^{2}\right]=&amp;amp;\frac{\alpha'_{B}\left(\alpha'_{B}+1\right)}{\left(\alpha'_{B}+\beta'_{B}\right)\left(\alpha'_{B}+\beta'_{B}+1\right)}+\frac{\alpha'_{A}\left(\alpha'_{A}+1\right)}{\left(\alpha'_{A}+\beta'_{A}\right)\left(\alpha'_{A}+\beta'_{A}+1\right)}\ldots\notag\\
&amp;amp;-2\frac{\alpha'_{A}}{\alpha'_{A}+\beta'_{A}}\frac{\alpha'_{B}}{\alpha'_{B}+\beta'_{B}}-\bar{\delta}_{BA}^{2}.\label{eq:var_diff}\end{align}&lt;/div&gt;
&lt;p&gt;The variance in the expected difference consists of the sum of two terms that are very nearly
- but interestingly not quite - the posterior variances of &lt;span class="math"&gt;\(p_B\)&lt;/span&gt; and &lt;span class="math"&gt;\(p_A\)&lt;/span&gt; minus
the square of the expected difference and a cross term.&lt;/p&gt;
&lt;p&gt;In the figure below I show a comparison of the expected difference and gain for
a single simulated experiment including the "&lt;span class="math"&gt;\(1\sigma\)&lt;/span&gt;" uncertainties (i.e. plus or minus the
square root of the variance in each measure). In this case the true difference
between &lt;span class="math"&gt;\(p_B\)&lt;/span&gt; and &lt;span class="math"&gt;\(p_A\)&lt;/span&gt; is 1%. After about 5000 trials, the two measures are
essentially the same.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Comparison of expected gain and difference for a simulated example." src="http://michaelryanbell.com/images/gain_and_diff_1percent.png"&gt;&lt;/p&gt;
&lt;p&gt;When the gain or difference is larger, the two quantities converge even more quickly.
But what about when the difference is negative? In this case, there is much more discrepancy
between the gain and the difference because the gain is a strictly positive quantity
while the difference can take both positive and negative values.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Comparison of expected gain and difference for a simulated example with negative difference." src="http://michaelryanbell.com/images/gain_and_diff_neg1percent.png"&gt;&lt;/p&gt;
&lt;p&gt;While I started by providing the gain and it's variance to build on the work of the blog posts
of Miller and Stuccio, I will actually opt to use the expected difference and it's
variance in my experiments.&lt;/p&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;So finally I have everything that I'll need to run basic experiments in situations
with binary outcomes. The expected difference (eq.&lt;span class="math"&gt;\(\,\ref{eq:exp_diff3}\)&lt;/span&gt;),
together with it's variance (eq.&lt;span class="math"&gt;\(\,\ref{eq:var_diff}\)&lt;/span&gt;), are enough to indicate not only how much better one
might do by switching to a new procedure, but also how much one should trust the
result. Experimental results can be monitored regularly as long as both the
difference and variance are evaluated at each step, and it's fine to
stop the experiment if the difference is found to be good enough when compared to the
uncertainty.&lt;/p&gt;
&lt;p&gt;These results apply to two procedure (A/B) tests where outcomes are binary. Similar
results can be obtained when testing 3 or more procedures in parallel or if
the outcomes are not binary but e.g. counts or rates instead. For example,
&lt;a href="http://www.evanmiller.org/bayesian-ab-testing.html"&gt;Evan Miller&lt;/a&gt; calculates POI
for count data and for three test groups. An expected difference and it's variance could
be calculated in these cases as well.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="statistics"></category><category term="data"></category></entry><entry><title>Closures in Python</title><link href="http://michaelryanbell.com/python_closures.html" rel="alternate"></link><published>2015-08-16T00:00:00-04:00</published><updated>2015-08-16T00:00:00-04:00</updated><author><name>Michael Bell</name></author><id>tag:michaelryanbell.com,2015-08-16:/python_closures.html</id><summary type="html">&lt;p&gt;The concept of &lt;a href="https://en.wikipedia.org/wiki/Closure_(computer_programming)"&gt;&lt;em&gt;closures&lt;/em&gt;&lt;/a&gt; is something that I've been 
familiar with for a while, but I haven't used in my own work until recently. I started thinking more about closures while reading 
&lt;a href="http://www.amazon.com/Software-Engineer-Learns-JavaScript-jQuery-ebook/dp/B00GAMTRI8"&gt;A Software Engineer Learns HTML5, JavaScript and jQuery&lt;/a&gt; 
by Dane Cameron (an excellent book, btw). They are introduced …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The concept of &lt;a href="https://en.wikipedia.org/wiki/Closure_(computer_programming)"&gt;&lt;em&gt;closures&lt;/em&gt;&lt;/a&gt; is something that I've been 
familiar with for a while, but I haven't used in my own work until recently. I started thinking more about closures while reading 
&lt;a href="http://www.amazon.com/Software-Engineer-Learns-JavaScript-jQuery-ebook/dp/B00GAMTRI8"&gt;A Software Engineer Learns HTML5, JavaScript and jQuery&lt;/a&gt; 
by Dane Cameron (an excellent book, btw). They are introduced in the book as a way to protect object members. 
In JS, like in Python, members of an object are public. In the absence of a &lt;em&gt;private&lt;/em&gt; keyword or the like, one can use 
closures to protect state variables from tampering by external code. Here's an example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="nx"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nx"&gt;f&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="nx"&gt;f&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="nx"&gt;f&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="p"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;What has happened here is that the function returned by &lt;code&gt;incrementer&lt;/code&gt; has "closed" over &lt;code&gt;i&lt;/code&gt;. &lt;code&gt;i&lt;/code&gt; is declared in the scope 
of &lt;code&gt;incrementer&lt;/code&gt; but is accessible within &lt;code&gt;function&lt;/code&gt;. Since &lt;code&gt;function&lt;/code&gt; refers to &lt;code&gt;i&lt;/code&gt;, the variable gets carried around 
by &lt;code&gt;function&lt;/code&gt; &lt;em&gt;even after &lt;code&gt;incrementer&lt;/code&gt; has returned.&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;The utility of this pattern is that &lt;code&gt;i&lt;/code&gt; can be modifed (incremented) by calling &lt;code&gt;f&lt;/code&gt;, the function returned by &lt;code&gt;incrementer&lt;/code&gt;, but 
it can't be accessed directly in any other way. &lt;/p&gt;
&lt;p&gt;I hadn't seen closures mentioned often in Python circles, at least not in scientific and data analysis contexts. But as I 
learned about closures in JS I couldn't help but wonder how they operate in Python, my language of choice. So does this 
same code pattern work in Python?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="o"&gt;---------------------------------------------------------------------------&lt;/span&gt;
&lt;span class="ne"&gt;UnboundLocalError&lt;/span&gt;                         &lt;span class="n"&gt;Traceback&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;most&lt;/span&gt; &lt;span class="n"&gt;recent&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;ipython&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;ec059b9bfe1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;----&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;ipython&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;fe458f37d60a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      &lt;span class="mi"&gt;2&lt;/span&gt;     &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
      &lt;span class="mi"&gt;3&lt;/span&gt;     &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;span class="o"&gt;----&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;         &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
      &lt;span class="mi"&gt;5&lt;/span&gt;         &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
      &lt;span class="mi"&gt;6&lt;/span&gt;     &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;

&lt;span class="ne"&gt;UnboundLocalError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;local&lt;/span&gt; &lt;span class="n"&gt;variable&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;i&amp;#39;&lt;/span&gt; &lt;span class="n"&gt;referenced&lt;/span&gt; &lt;span class="n"&gt;before&lt;/span&gt; &lt;span class="n"&gt;assignment&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Nope. We get an &lt;code&gt;UnboundLocalError&lt;/code&gt;. What if we just refer to &lt;code&gt;i&lt;/code&gt; rather than try to increment it's value?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="mi"&gt;120&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That works fine. Well, &lt;code&gt;incrementer&lt;/code&gt; no longer increments anything, but at least the code executes without error. So what 
happened here? In Python, you can access a variable from a parent scope, but you can't overwrite it. Assignment in Python is
done within the local scope, even if a variable with the same name is declared in a parent 
scope. The parent variable is not overridden, but instead a new variable is created in the nested scope. 
Take the following code for example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="mi"&gt;10&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;i&lt;/code&gt; declared in &lt;code&gt;function&lt;/code&gt; is local to the nested function and "shadows" the &lt;code&gt;i&lt;/code&gt; declared in &lt;code&gt;incrementer&lt;/code&gt;.  &lt;/p&gt;
&lt;p&gt;Although we can't overwrite a variable in a parent scope, we can modify its contents &lt;em&gt;if the object is a 
mutable type&lt;/em&gt; like a list or an object. So to replicate the JS style closure in Python, one could close over a
mutable object, e.g.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def get_incrementer():
    i = [0]
    def function():
        i[0] += 1
        return i[0]
    return function

&amp;gt;&amp;gt; f = get_incrementer()
&amp;gt;&amp;gt; f()
1
&amp;gt;&amp;gt; f()
2
&amp;gt;&amp;gt; f()
3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let's say that instead of using the pattern given above, we defined &lt;code&gt;incrementer&lt;/code&gt; to be a method of a class and used it 
to increment a normal class attribute.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MyClass&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_i&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_i&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MyClass&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; 
&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;incrementer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="mi"&gt;101&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This works, but of course one can always just modify &lt;code&gt;test._i&lt;/code&gt;, so subsequent calls to incrementer might not always 
behave as expected. &lt;/p&gt;
&lt;p&gt;So closures can be used to protect a variable. I don't think I've come across anyone that does this in practice, and I've 
seen some discussion that it might not be a good idea, but I don't really understand why. &lt;/p&gt;
&lt;p&gt;A much more common use case for closures in Python, and one that I now make use of myself, is 
&lt;a href="https://www.python.org/dev/peps/pep-0318/"&gt;&lt;em&gt;function decoration&lt;/em&gt;&lt;/a&gt;. Function decorators 
are a powerful concept that allow you to modify a function's behavior without changing its implementation. &lt;/p&gt;
&lt;p&gt;For example, let's say you're writing an application and decide you want to log every call to a set of functions. 
You could implement your functions to have logging statements sprinkled throughout, mixing logging code together with
the rest of your code. But this makes for code that is hard to read and maintain. &lt;/p&gt;
&lt;p&gt;Instead, you can use a function decorator to handle the logging for you keeping the logging features separate from your 
application code. This is called &lt;a href="https://en.wikipedia.org/wiki/Separation_of_concerns"&gt;&lt;em&gt;separation of concerns&lt;/em&gt;&lt;/a&gt; and is 
central to a programming paradigm known as &lt;a href="https://en.wikipedia.org/wiki/Aspect-oriented_programming"&gt;&lt;em&gt;aspect oriented programming&lt;/em&gt;&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Let's write a logging decorator that logs the name of the function call, the arguments passed to the function, and 
the return value.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;log_me&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;function_wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Calling function {:}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;func_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;args_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Positional arguments: {:}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args_list&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Keyword arguments: {:}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# Call the original function&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Return: {:}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;function_wrapper&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;log_me&lt;/code&gt; takes a function as an argument and returns a function (a decorator must return a function). The function that 
we return, defined within the scope of &lt;code&gt;log_me&lt;/code&gt; is called &lt;code&gt;function_wrapper&lt;/code&gt; and it closes over the argument &lt;code&gt;func&lt;/code&gt;. 
&lt;code&gt;function_wrapper&lt;/code&gt; takes in a set of arguments, logs them, calls the decorated function &lt;code&gt;func&lt;/code&gt;, and finally
logs the result. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A side note&lt;/strong&gt; I know I'm not really "logging" here, per se, but just printing to standard output. In principle one should 
use the &lt;a href="https://docs.python.org/2/library/logging.html"&gt;logging module&lt;/a&gt; or something similar.&lt;/p&gt;
&lt;p&gt;To &lt;em&gt;use&lt;/em&gt; &lt;code&gt;log_me&lt;/code&gt; we can use the Python decorator syntax (which you're familiar with if you've used e.g. &lt;a href="http://flask.pocoo.org/"&gt;flask&lt;/a&gt; 
or many other popular Python packages that use decorators):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@log_me
def adder(a, b, **kwargs):
    return a + b

@log_me
def multiplier(a, b, **kwargs):
    return a * b
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here I've defined two simple functions and decorated them with &lt;code&gt;log_me&lt;/code&gt;. Equivalently I could have just done:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def multiplier(a, b, **kwargs):
    return a * b
multiplier = log_me(multiplier)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Anyway, the result is that when I call either of these two functions, their inputs and outputs get logged.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt;&amp;gt; adder(1,2, another=&amp;#39;argument&amp;#39;)
Calling function adder
Positional arguments: 1 2
Keyword arguments: {&amp;#39;another&amp;#39;: &amp;#39;argument&amp;#39;}
Return: 3

&amp;gt;&amp;gt; multiplier(3, 4, another=&amp;#39;argument&amp;#39;)
Calling function multiplier
Positional arguments: 1 2
Keyword arguments: {&amp;#39;another&amp;#39;: &amp;#39;argument&amp;#39;}
Return: 12
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is really cool. We have now separated the logging code entirely from the rest of our code, making everything
easier to read and maintain. It's also super easy to start logging new functions. Just add the &lt;code&gt;log_me&lt;/code&gt; decorator! And
all of this is made possible by closures.&lt;/p&gt;</content><category term="python"></category></entry><entry><title>Processing whole files from S3 with Spark</title><link href="http://michaelryanbell.com/processing-whole-files-spark-s3.html" rel="alternate"></link><published>2015-02-11T00:00:00-05:00</published><updated>2015-02-11T00:00:00-05:00</updated><author><name>Michael Bell</name></author><id>tag:michaelryanbell.com,2015-02-11:/processing-whole-files-spark-s3.html</id><summary type="html">&lt;p&gt;I have recently started diving into &lt;a href="https://spark.apache.org/"&gt;Apache Spark&lt;/a&gt; for a project at work and ran into issues trying to process the contents of a collection of files in parallel, particularly when the files are stored on Amazon S3. In this post I describe my problem and how I got around …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have recently started diving into &lt;a href="https://spark.apache.org/"&gt;Apache Spark&lt;/a&gt; for a project at work and ran into issues trying to process the contents of a collection of files in parallel, particularly when the files are stored on Amazon S3. In this post I describe my problem and how I got around it.&lt;/p&gt;
&lt;p&gt;My first Spark project is simple. I have a single function that processes data from a file and a lot of data files to process using this function. It should be trivial to distribute this task, right? Just create an RDD (Spark's core data container, basically a distributed collection whose items can be operated on in parallel) where each item contains the contents of a single file and apply my function using the RDD methods &lt;code&gt;foreach&lt;/code&gt; or &lt;code&gt;map&lt;/code&gt; if I want to capture results for logging or something. &lt;/p&gt;
&lt;p&gt;Most examples I found for &lt;code&gt;pyspark&lt;/code&gt; create RDDs using the &lt;code&gt;SparkContext.textFile()&lt;/code&gt; method. This generates an RDD where each line of the file is an item in the collection. This is not what I want. Looking through the API docs I found the method &lt;code&gt;SparkContext.wholeTextFiles()&lt;/code&gt; that appears to do exactly what I want. I can point this method to a directory and it will create an RDD where each item contains data from an entire file. Perfect! Well, it would be if it worked anyway.&lt;/p&gt;
&lt;p&gt;Here's the issue... our data files are stored on Amazon S3, and for whatever reason this method fails when reading data from S3 (using Spark v1.2.0). I'm using &lt;a href="https://spark.apache.org/docs/1.2.1/api/python/pyspark.html"&gt;&lt;code&gt;pyspark&lt;/code&gt;&lt;/a&gt; but I've read in forums that people are having the same issue with the Scala library, so it's not just a Python issue. Anyway, here's how I got around this problem.&lt;/p&gt;
&lt;p&gt;First, I create a listing of files in a root directory and store the listing in a text file in a scratch bucket on S3. Here is a code snippet (I'm using &lt;a href="https://boto.readthedocs.org/en/latest/"&gt;&lt;code&gt;boto&lt;/code&gt;&lt;/a&gt; to interact with S3):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;boto&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect_s3&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# bucket is the name of the S3 bucket where your data resides&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_bucket&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bucket&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="c1"&gt;# inkey_root is the S3 &amp;#39;directory&amp;#39; in which your files are located&lt;/span&gt;
&lt;span class="n"&gt;keys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prefix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;inkey_root&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;key_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next I need a function that takes a file path, parses the data from the file into a string, and returns a tuple with the file name and contents (as a string). Here is just such a function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fetch_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s3key&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Fetch data with the given s3 key and pass along the contents as a string.&lt;/span&gt;

&lt;span class="sd"&gt;    :param s3key: An s3 key path string.&lt;/span&gt;
&lt;span class="sd"&gt;    :return: A tuple (file_name, data) where data is the contents of the &lt;/span&gt;
&lt;span class="sd"&gt;        file in a string. Note that if the file is compressed the string will &lt;/span&gt;
&lt;span class="sd"&gt;        contain the compressed data which will have to be unzipped using the &lt;/span&gt;
&lt;span class="sd"&gt;        gzip package.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;boto&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;connect_s3&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_bucket&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bucket&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s3key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_contents_as_string&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# I use basename() to get just the file name itself&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;basename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s3key&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then I create an RDD using &lt;code&gt;parallelize&lt;/code&gt; on the listing of files to process. The RDD items will be the paths (ok fine, &lt;em&gt;keys&lt;/em&gt;) of the files that I want to process in S3.  Then I call the RDD's &lt;code&gt;map&lt;/code&gt; method, using &lt;code&gt;fetch_data&lt;/code&gt; to parse the files and pass their contents along as a new RDD with the file contents as items, just like I wanted from &lt;code&gt;wholeTextFiles&lt;/code&gt; in the first place. Then you can go ahead and process the resulting data as necessary, e.g. by chaining a call to another &lt;code&gt;map&lt;/code&gt;, &lt;code&gt;foreach&lt;/code&gt; or whatever. Here's the code, with a chained call to &lt;code&gt;foreach&lt;/code&gt; to process the data using a function &lt;code&gt;process_data&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyspark&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SparkContext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;local&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Whatever&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Create an RDD from the list of s3 key names to process stored in key_list&lt;/span&gt;
&lt;span class="n"&gt;file_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parallelize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key_list&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;file_list&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fetch_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;foreach&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;process_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So there you have it, a simple way to get around the fact that Spark's &lt;code&gt;wholeTextFiles&lt;/code&gt; (as of now) does not work with files stored in S3.&lt;/p&gt;</content><category term="spark"></category><category term="how-to"></category></entry><entry><title>Spell checking an IPython notebook</title><link href="http://michaelryanbell.com/ipynb-spellchecking.html" rel="alternate"></link><published>2015-02-01T00:00:00-05:00</published><updated>2015-02-01T00:00:00-05:00</updated><author><name>Michael Bell</name></author><id>tag:michaelryanbell.com,2015-02-01:/ipynb-spellchecking.html</id><summary type="html">&lt;p&gt;I've been using &lt;a href="http://ipython.org/notebook.html"&gt;IPython notebooks&lt;/a&gt; a lot lately for both my personal and professional
research and analysis projects. It's a great tool for keeping code, visualization and analysis together in one place.
It's also convenient for communicating results. Just export your notebook to HTML and it's ready to distribute... except …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been using &lt;a href="http://ipython.org/notebook.html"&gt;IPython notebooks&lt;/a&gt; a lot lately for both my personal and professional
research and analysis projects. It's a great tool for keeping code, visualization and analysis together in one place.
It's also convenient for communicating results. Just export your notebook to HTML and it's ready to distribute... except
for the fact that without a spell checker I tend to have a lot of typos in my markdown cells.&lt;/p&gt;
&lt;p&gt;I found a work-around that enables spell checking in the markdown cells of my notebooks from GitHub user
&lt;a href="https://github.com/dsblank"&gt;dsblank&lt;/a&gt; in the comments of the IPython project issue
&lt;a href="https://github.com/ipython/ipython/issues/3216"&gt;here&lt;/a&gt;. It is a bit hack-y and tedious but it works.&lt;/p&gt;
&lt;p&gt;To enable spell checking, do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install a custom extension with the following command&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ipython install-nbextension https://bitbucket.org/ipre/calico/downloads/calico-spell-check-1.0.zip
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Execute the following code in a cell of your notebook&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;%%javascript&lt;/span&gt;
&lt;span class="n"&gt;IPython&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_extensions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;calico-spell-check&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You should now see a new button in the tool bar that, when checked, enables spell checking within your markdown cells.&lt;/p&gt;
&lt;p&gt;This functionality will only last for the current session of the current notebook. You'll have to repeat step 2 for each
notebook and for every session. &lt;strong&gt;And be sure to delete or comment the code from step 2 once you've executed it.&lt;/strong&gt; I've
found that it causes problems (unexecutable markdown cells) if you happen to execute that block of code twice in one
session.&lt;/p&gt;
&lt;p&gt;Apart from the tedium of this solution, I've found that it works rather well. Hopefully this functionality will make it
into future release of the IPython notebook.&lt;/p&gt;</content><category term="python"></category><category term="how-to"></category></entry></feed>